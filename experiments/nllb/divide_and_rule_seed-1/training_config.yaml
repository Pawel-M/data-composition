results_dir: .
results_suffix: null
tokenizer_name: 'nllb-ctx'
model_path: "facebook/nllb-200-distilled-600M"
tokenizer_path: "facebook/nllb-200-distilled-600M"
max_length: 1024
lang_pairs:
  - "en-de"
  - "de-en"
  - "en-es"
  - "es-en"
  - "en-fr"
  - "fr-en"
  - "en-pl"
  - "pl-en"
  - "en-ru"
  - "ru-en"
src_ctx_size: 3
tgt_ctx_size: 3
seed: 1

datasets:
  - # OS random
    dataset_name: opensubtitles
    raw_dataset_path: ctxPro_path/data/opensubs/
    dataset_path: path/to/repo/data/hf_opensubtitles
    dataset_annotation_path: ctxPro_path/release
    train_size: 50_000
    split_seed: 1
    sample_ctx_size: true
    lang_pairs:
      - "en-de"
      - "de-en"
      - "en-es"
      - "es-en"
      - "en-fr"
      - "fr-en"
      - "en-pl"
      - "pl-en"
      - "en-ru"
      - "ru-en"

only_divided_dataset: true

training_arguments:
  optim: adafactor
  learning_rate: 0.00001
  lr_scheduler_type: inverse_sqrt
  warmup_ratio: 0.1
  per_device_train_batch_size: 32
  per_device_eval_batch_size: 32
  gradient_accumulation_steps: 16
  weight_decay: 0.01
  save_total_limit: 1
  num_train_epochs: 10
  fp16: true